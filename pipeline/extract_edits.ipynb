{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Edits Data Pipeline\n",
    "\n",
    "This notebook demonstrates a simple ETL pipeline that:\n",
    "1. Extracts data from the Wikipedia REST API\n",
    "2. Transforms it to JSON Lines format\n",
    "3. Uploads directly to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your Username\n",
    "\n",
    "Pick a unique username (e.g., your name or initials) and use it consistently:\n",
    "\n",
    "- **S3 Bucket**: `<username>-wikidata` (e.g., `johndoe-wikidata`)\n",
    "- **Athena Database**: `<username>` (e.g., `johndoe`)\n",
    "- **Lambda**: Use the same `<username>-wikidata` bucket\n",
    "\n",
    "**Important:** No hyphens in database names! Use underscores if needed (e.g., `john_doe`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your username here - use it consistently across all resources\n",
    "USERNAME = \"<etnav>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract: Retrieve Data from Wikipedia API\n",
    "\n",
    "We use the Wikimedia Analytics API to fetch the most edited pages for a specific date. The API returns JSON with page titles and edit counts.\n",
    "\n",
    "**API Documentation:** https://doc.wikimedia.org/generated-data-platform/aqs/analytics-api/reference/edits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting REST API URL: https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/user/content/2025/11/25\n",
      "Wikipedia REST API Response body: {\"items\":[{\"project\":\"en.wikipedia\",\"editor-type\":\"user\",\"page-type\":\"content\",\"granularity\":\"daily\",\"results\":[{\"timestamp\":\"2025-11-25T00:00:00.000Z\",\"top\":[{\"page_title\":\"Akiko_Nakamura\",\"edits\":143,\"rank\":1},{\"page_title\":\"2026_Men's_T20_World_Cup\",\"edits\":110,\"rank\":2},{\"page_title\":\"Udit_Narayan\",\"edits\":105,\"rank\":3},{\"page_title\":\"2010_Iowa_House_of_Representatives_election\",\"edits\":99,\"rank\":4},{\"page_title\":\"Cyprus_Basketball_Division_A\",\"edits\":80,\"rank\":5},{\"page_title\":\"2025_UK_Cham...\n",
      "Wikipedia REST API Response Code: 200\n",
      "Successfully retrieved Wikipedia data, content-length: 6284\n"
     ]
    }
   ],
   "source": [
    "# Try different dates to see how the data changes\n",
    "DATE_PARAM = \"2025-11-25\"\n",
    "\n",
    "date = datetime.datetime.strptime(DATE_PARAM, \"%Y-%m-%d\")\n",
    "\n",
    "# Construct the API URL\n",
    "url = f\"https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/user/content/{date.strftime('%Y/%m/%d')}\"\n",
    "print(f\"Requesting REST API URL: {url}\")\n",
    "\n",
    "# Make the API request\n",
    "wiki_server_response = requests.get(url, headers={\"User-Agent\": \"curl/7.68.0\"})\n",
    "wiki_response_status = wiki_server_response.status_code\n",
    "wiki_response_body = wiki_server_response.text\n",
    "\n",
    "print(f\"Wikipedia REST API Response body: {wiki_response_body[:500]}...\")\n",
    "print(f\"Wikipedia REST API Response Code: {wiki_response_status}\")\n",
    "\n",
    "# Validate response\n",
    "if wiki_response_status != 200:\n",
    "    raise Exception(f\"Received non-OK status code from Wiki Server: {wiki_response_status}\")\n",
    "print(f\"Successfully retrieved Wikipedia data, content-length: {len(wiki_response_body)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform: Process Raw Data into JSON Lines\n",
    "\n",
    "Convert the raw API response into a structured JSON Lines format suitable for analytics. Each line is a valid JSON object representing one page's edit statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 100 records to JSON Lines\n",
      "First few lines:\n",
      "{\"title\": \"Akiko_Nakamura\", \"edits\": 143, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-23T19:25:35.351974\"}\n",
      "{\"title\": \"2026_Men's_T20_World_Cup\", \"edits\": 110, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-23T19:25:35.351974\"}\n",
      "{\"title\": \"Udit_Narayan\", \"edits\": 105, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-23T19:25:35.351974\"}\n",
      "{\"title\": \"2010_Iowa_House_of_Representatives_election\", \"edits\": 99, \"date\": \"2025-11-25\", \"retrieved_at\": \"2025-12-23T19:25:35.351974\"}\n",
      "{\"title\": \"Cyprus_Basket...\n"
     ]
    }
   ],
   "source": [
    "# Parse the API response and extract top edits\n",
    "wiki_response_parsed = wiki_server_response.json()\n",
    "top_edits = wiki_response_parsed[\"items\"][0][\"results\"][0][\"top\"]\n",
    "\n",
    "# Transform to JSON Lines format\n",
    "current_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "json_lines = \"\"\n",
    "for page in top_edits[:5]:\n",
    "    record = {\n",
    "        \"title\": page[\"page_title\"],\n",
    "        \"edits\": page[\"edits\"],\n",
    "        \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "        \"retrieved_at\": current_time.replace(tzinfo=None).isoformat(),\n",
    "    }\n",
    "    json_lines += json.dumps(record) + \"\\n\"\n",
    "\n",
    "print(f\"Transformed {len(top_edits)} records to JSON Lines\")\n",
    "print(f\"First few lines:\\n{json_lines[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab 1: Create an S3 Bucket\n",
    "\n",
    "**Task:** Create an S3 bucket for the Wikipedia data pipeline.\n",
    "\n",
    "**Requirements:**\n",
    "- Bucket name: `<username>-wikidata` (use your USERNAME from above)\n",
    "- Create the bucket if it doesn't exist\n",
    "\n",
    "**Documentation:** [create_bucket](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/create_bucket.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing bucket: etnav-wikidata\n"
     ]
    }
   ],
   "source": [
    "S3_WIKI_BUCKET = \"etnav-wikidata\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "bucket_names = [bucket[\"Name\"] for bucket in s3.list_buckets()[\"Buckets\"]]\n",
    "\n",
    "if S3_WIKI_BUCKET not in bucket_names:\n",
    "    s3.create_bucket(Bucket=S3_WIKI_BUCKET)\n",
    "    print(f\"Created new bucket: {S3_WIKI_BUCKET}\")\n",
    "else:\n",
    "    print(f\"Using existing bucket: {S3_WIKI_BUCKET}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket etnav-wikidata exists!\n"
     ]
    }
   ],
   "source": [
    "# Test Lab 1\n",
    "assert USERNAME != \"etnav\", \"Please set your USERNAME at the top of the notebook\"\n",
    "assert S3_WIKI_BUCKET.endswith(\"-wikidata\"), \"Bucket name must end with '-wikidata'\"\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=S3_WIKI_BUCKET)\n",
    "    print(f\"Bucket {S3_WIKI_BUCKET} exists!\")\n",
    "except Exception as e:\n",
    "    print(f\"Bucket {S3_WIKI_BUCKET} not found: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab 2: Upload JSON Lines to S3\n",
    "\n",
    "**Task:** Upload the `json_lines` data directly to S3 (no local file!).\n",
    "\n",
    "**Requirements:**\n",
    "- Use `s3.put_object()` to upload the data directly\n",
    "- Place the file under `raw-edits/` prefix in S3\n",
    "- File name: `raw-edits-YYYY-MM-DD.json` (use the date from `DATE_PARAM`)\n",
    "\n",
    "**Example S3 path:** `s3://johndoe-wikidata/raw-edits/raw-edits-2025-11-25.json`\n",
    "\n",
    "**Documentation:** [put_object](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_object.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB 2: Upload json_lines directly to S3\n",
    "# YOUR SOLUTION COMES HERE =========================\n",
    "\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully to s3://etnav-wikidata/raw-edits/raw-edits-2025-11-25.json\n"
     ]
    }
   ],
   "source": [
    "# Test Lab 2\n",
    "expected_key = f\"raw-edits/raw-edits-{date.strftime('%Y-%m-%d')}.json\"\n",
    "try:\n",
    "    s3.head_object(Bucket=S3_WIKI_BUCKET, Key=expected_key)\n",
    "    print(f\"File uploaded successfully to s3://{S3_WIKI_BUCKET}/{expected_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"File not found at s3://{S3_WIKI_BUCKET}/{expected_key}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in raw-edits/:\n",
      " - raw-edits/raw-edits-2025-11-01.json\n",
      " - raw-edits/raw-edits-2025-11-19.json\n",
      " - raw-edits/raw-edits-2025-11-20.json\n",
      " - raw-edits/raw-edits-2025-11-21.json\n",
      " - raw-edits/raw-edits-2025-11-22.json\n",
      " - raw-edits/raw-edits-2025-11-23.json\n",
      " - raw-edits/raw-edits-2025-11-24.json\n",
      " - raw-edits/raw-edits-2025-11-25.json\n",
      " - raw-edits/raw-edits-2025-11-26.json\n",
      " - raw-edits/raw-edits-2025-11-27.json\n",
      " - raw-edits/raw-edits-2025-11-28.json\n",
      " - raw-edits/raw-edits-2025-11-29.json\n",
      " - raw-edits/raw-edits-2025-11-30.json\n"
     ]
    }
   ],
   "source": [
    "# List all raw-edits files in S3\n",
    "\n",
    "response = s3.list_objects_v2(\n",
    "    Bucket=S3_WIKI_BUCKET,\n",
    "    Prefix=\"raw-edits/\"\n",
    ")\n",
    "\n",
    "files = [obj[\"Key\"] for obj in response.get(\"Contents\", [])]\n",
    "\n",
    "print(\"Files in raw-edits/:\")\n",
    "for f in files:\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_PARAM = \"2025-11-23\"\n",
    "DATE_PARAM = \"2025-11-24\"\n",
    "DATE_PARAM = \"2025-11-25\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
